{
  "source": "tools-in-data-science-public\\retrieval-augmented-generation.md",
  "type": "course",
  "text": "## Retrieval Augmented Generation\n\nThe video is not available yet. Please review the notebook, which is self-explanatory. #TODO\n\nYou will learn to implement Retrieval Augmented Generation (RAG) to enhance language models' responses by incorporating relevant context, covering:\n\n- **LLM Context Limitations**: Understanding the constraints of context windows in large language models.\n- **Retrieval Augmented Generation**: The technique of retrieving and using relevant documents to enhance model responses.\n- **Embeddings**: How to convert text into numerical representations that are used for similarity calculations.\n- **Similarity Search**: Finding the most relevant documents by calculating cosine similarity between embeddings.\n- **OpenAI API Integration**: Using the OpenAI API to generate responses based on the most relevant documents.\n- **Tourist Recommendation Bot**: Building a bot that recommends tourist attractions based on user interests using embeddings.\n- **Next Steps for Implementation**: Insights into scaling the solution with a vector database, re-rankers, and improved prompts for better accuracy and efficiency.\n\nHere are the links used in the video:\n\n- [Jupyter Notebook](https://colab.research.google.com/drive/1x-g0kjktFkBcujJssKrx1xhZarsQA0ya)\n- [`gte-large-en-v1.5` embedding model](https://huggingface.co/Alibaba-NLP/gte-large-en-v1.5)\n- [Awesome vector database](https://github.com/mileszim/awesome-vector-database)\n"
}