{
  "source": "tools-in-data-science-public\\llm.md",
  "type": "course",
  "text": "## LLM CLI: llm\n\n[`llm`](https://pypi.org/project/llm) is a command-line utility for interacting with large language models\u2014simplifying prompts, managing models and plugins, logging every conversation, and extracting structured data for pipelines.\n\n[![Language models on the command-line w/ Simon Willison](https://i.ytimg.com/vi_webp/QUXQNi6jQ30/sddefault.webp)](https://youtu.be/QUXQNi6jQ30?t=100)\n\n### Basic Usage\n\n[Install llm](https://github.com/simonw/llm#installation). Then set up your [`OPENAI_API_KEY`](https://platform.openai.com/api-keys) environment variable. See [Getting started](https://github.com/simonw/llm?tab=readme-ov-file#getting-started).\n\n**TDS Students**: See [Large Language Models](large-language-models.md) for instructions on how to get and use `OPENAI_API_KEY`.\n\n```bash\n# Run a simple prompt\nllm 'five great names for a pet pelican'\n\n# Continue a conversation\nllm -c 'now do walruses'\n\n# Start a memory-aware chat session\nllm chat\n\n# Specify a model\nllm -m gpt-4.1-nano 'Summarize tomorrow\u2019s meeting agenda'\n\n# Extract JSON output\nllm 'List the top 5 Python viz libraries with descriptions' \\\n  --schema-multi 'name,description'\n```\n\nOr use llm without installation using [`uvx`](uv.md):\n\n```bash\n# Run llm via uvx without any prior installation\nuvx llm 'Translate \"Hello, world\" into Japanese'\n\n# Specify a model\nuvx llm -m gpt-4.1-nano 'Draft a 200-word blog post on data ethics'\n\n# Use structured JSON output\nuvx llm 'List the top 5 programming languages in 2025 with their release years' \\\n  --schema-multi 'rank,language,release_year'\n```\n\n### Key Features\n\n- **Interactive prompts**: `llm '\u2026'` \u2014 Fast shell access to any LLM.\n- **Conversational flow**: `-c '\u2026'` \u2014 Continue context across prompts.\n- **Model switching**: `-m MODEL` \u2014 Use OpenAI, Anthropic, local models, and more.\n- **Structured output**: `llm json` \u2014 Produce JSON for automation.\n- **Logging & history**: `llm logs path` \u2014 Persist every prompt/response in SQLite.\n- **Web UI**: `datasette \"$(llm logs path)\"` \u2014 Browse your entire history with Datasette.\n- **Persistent chat**: `llm chat` \u2014 Keep the model in memory across multiple interactions.\n- **Plugin ecosystem**: `llm install PLUGIN` \u2014 Add support for new models, data sources, or workflows. ([Language models on the command-line - Simon Willison's Weblog](https://simonwillison.net/2024/Jun/17/cli-language-models/?utm_source=chatgpt.com))\n\n### Practical Uses\n\n- **Automated coding**. Generate code scaffolding, review helpers, or utilities on demand. For example, after running`llm install llm-cmd`, run `llm cmd 'Undo the last git commit'`. Inspired by [Simon\u2019s post on using LLMs for rapid tool building](https://simonwillison.net/2025/Mar/11/using-llms-for-code/).\n- **Transcript processing**. Summarize YouTube or podcast transcripts using Gemini. See [Putting Gemini 2.5 Pro through its paces](https://www.macstories.net/mac/llm-youtube-transcripts-with-claude-and-gemini-in-shortcuts/).\n- **Commit messages**. Turn diffs into descriptive commit messages, e.g. `git diff | llm 'Write a concise git commit message explaining these changes'`. \\\n- **Data extraction**. Convert free-text into structured JSON for automation. [Structured data extraction from unstructured content using LLM schemas](https://simonwillison.net/2025/Feb/28/llm-schemas/).\n"
}