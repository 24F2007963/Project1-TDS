{
  "source": "tools-in-data-science-public\\large-language-models.md",
  "type": "course",
  "text": "# Large Language Models\n\nThis module covers the practical usage of large language models (LLMs).\n\n**LLMs incur a cost.** For the May 2025 batch, use [aipipe.org](https://aipipe.org/) as a proxy.\nEmails with `@ds.study.iitm.ac.in` get a **$1 per calendar month** allowance. (Don't exceed that.)\n\nRead the [AI Pipe documentation](https://github.com/sanand0/aipipe) to learn how to use it. But in short:\n\n1. Replace `OPENAI_BASE_URL`, i.e. `https://api.openai.com/v1` with `https://aipipe.org/openrouter/v1...` or `https://aipipe.org/openai/v1...`\n2. Replace `OPENAI_API_KEY` with the [`AIPIPE_TOKEN`](https://aipipe.org/login)\n3. Replace model names, e.g. `gpt-4.1-nano`, with `openai/gpt-4.1-nano`\n\nFor example, let's use [Gemini 2.0 Flash Lite](https://cloud.google.com/vertex-ai/generative-ai/docs/models/gemini/2-0-flash-lite) via [OpenRouter](https://openrouter.ai/google/gemini-2.0-flash-lite-001) for chat completions and [Text Embedding 3 Small](https://platform.openai.com/docs/models/text-embedding-3-small) via [OpenAI](https://platform.openai.com/docs/) for embeddings:\n\n```bash\ncurl https://aipipe.org/openrouter/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $AIPIPE_TOKEN\" \\\n  -d '{\n    \"model\": \"google/gemini-2.0-flash-lite-001\",\n    \"messages\": [{ \"role\": \"user\", \"content\": \"What is 2 + 2?\"} }]\n  }'\n\ncurl https://aipipe.org/openai/v1/embeddings \\\n  -H \"Content-Type: application/json\" \\\n  -H \"Authorization: Bearer $AIPIPE_TOKEN\" \\\n  -d '{ \"model\": \"text-embedding-3-small\", \"input\": \"What is 2 + 2?\" }'\n```\n\nOr using [`llm`](https://llm.datasette.io/):\n\n```bash\nllm keys set openai --value $AIPIPE_TOKEN\n\nexport OPENAI_BASE_URL=https://aipipe.org/openrouter/v1\nllm 'What is 2 + 2?' -m openrouter/google/gemini-2.0-flash-lite-001\n\nexport OPENAI_BASE_URL=https://aipipe.org/openai/v1\nllm embed -c 'What is 2 + 2' -m 3-small\n```\n\n**For a 50% discount** (but slower speed), use [Flex processing](https://platform.openai.com/docs/guides/flex-processing) by adding `service_tier: \"flex\"` to your JSON request.\n\n## AI Proxy - Jan 2025\n\nFor the Jan 2025 batch, we had created API keys for everyone with an `iitm.ac.in` email to use `gpt-4o-mini` and `text-embedding-3-small`. Your usage is limited to **$1 per calendar month** for this course. Don't exceed that.\n\n**Use [AI Proxy](https://github.com/sanand0/aiproxy)** instead of OpenAI. Specifically:\n\n1. Replace your API to `https://api.openai.com/...` with `https://aiproxy.sanand.workers.dev/openai/...`\n2. Replace the `OPENAI_API_KEY` with the `AIPROXY_TOKEN` that someone will give you.\n"
}